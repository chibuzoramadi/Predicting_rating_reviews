{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uit8206FzNPM"
      },
      "source": [
        "Machine Learning, Atificial Neural Networks and Deep Learning Examination ~~ **Chibuzor John Amadi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk5GtnkF0S_o"
      },
      "source": [
        "#  - Problem and Initial Intuition. Q1\n",
        "\n",
        "We are tasked with a dataset of an amusement park with visitor's reviews, the dataset contains 6 unique columns and the objective is to study this columns and create a deep neural network model that predicts the rating value of the reviews. \"Rating\" noted is a column in the dataset.\n",
        "The following text cells will illustrate how I will handle each individual column and build a suitable model to carry out the best possible prediction.\n",
        "\n",
        "## Model Architecture\n",
        "For model Architecture I will be using a Recurrent Neural Network, typically I will construct all my experiments of this model with an LSTM or its variants like the GRU  \n",
        "\n",
        "## (QUESTION 1: INPUT)\n",
        "\n",
        "- The \"Review_Text\"and the \"Branch\" columns will be processed and trained and used for predicting the rating\n",
        "\n",
        "After studying the characteristics of the 6 columns of the dataset i have made the following conclusions:\n",
        "1.  **Review ID**: I believe this is solely the Identification number of the    individual making the review, in relation to the problem at hand this column will be dropped.\n",
        "2. **Rating**: ranging from 1 to 5, with 1 being **'unsatisfied'** and 5 being **'satisfied'** I will carry out a transformation that changes '1', '2', '3' to a \"0\" rating and '4', '5' to a \"1\" rating.\n",
        "Although my decision to classify '3' as a bad rating seems strict, I personally feel that for the task at hand a rating of 3 not be classified as **'satisfied'**. I am using this transformation in order to carry out a binary classification.\n",
        "3. **Year Month**: I will drop the column because it does not impact the the specific problem we have at hand and will not affect the prediction of the rating values. It would be helpfulhowever if we were looking for a time specific rating value prediction.\n",
        "4. **Review Location**: I will drop this column of strings as well because unless we are looking for a specific location problem with the ratings. it general does not impact the raring value prediction.\n",
        "5. **Review Text**: this is the main column we will use to predict the ratings values, it contains text of the each visitors reviews which is more or less unique. We can exploit Natural Language Processing techniques to transform this text reviews and then find similarities and make classification.\n",
        "Each text review will be transformed into dense vectors and the we can do this with word embedding strategies like word2vec and GloVe.\n",
        "6. **Branch**: I would apply a pre-processing technique called one-hot encoding to form, for example [0, 1, 2] to represent Branch 1, 2 and 3 respectively, i.e. the calfornia, hong-kong and paris branch.\n",
        "\n",
        "The input is of word-level representation, each word is represented as a vector. where each word is represented by a word embedding vector, which is a **dense vector** representation of the word in a continuous vector space. The input sequence of words forms a matrix, where each row represents a word vector.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8JTAshV-iD6"
      },
      "source": [
        "## DATA PRE-PREPROCESSING\n",
        "\n",
        "I will begin by import the dataset from a github link, after which I will study the size and feature of the dataset to see exactly how to carry out my preprocessing method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdL4RLIIu0Yb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# importing dataset from a kaggle competition ]\n",
        "#https://www.kaggle.com/datasets/arushchillar/disneyland-reviews?resource=download\n",
        "\n",
        "data = pd.read_csv('DisneylandReviews')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cIY9KWY2AO1L",
        "outputId": "bcf6ca1f-ad59-47ad-eb27-538d5a1a274d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Review_ID  Rating Year_Month     Reviewer_Location  \\\n",
              "0      670772142       4     2019-4             Australia   \n",
              "1      670682799       4     2019-5           Philippines   \n",
              "2      670623270       4     2019-4  United Arab Emirates   \n",
              "3      670607911       4     2019-4             Australia   \n",
              "4      670607296       4     2019-4        United Kingdom   \n",
              "...          ...     ...        ...                   ...   \n",
              "42651    1765031       5    missing        United Kingdom   \n",
              "42652    1659553       5    missing                Canada   \n",
              "42653    1645894       5    missing          South Africa   \n",
              "42654    1618637       4    missing         United States   \n",
              "42655    1536786       4    missing        United Kingdom   \n",
              "\n",
              "                                             Review_Text               Branch  \n",
              "0      If you've ever been to Disneyland anywhere you...  Disneyland_HongKong  \n",
              "1      Its been a while since d last time we visit HK...  Disneyland_HongKong  \n",
              "2      Thanks God it wasn   t too hot or too humid wh...  Disneyland_HongKong  \n",
              "3      HK Disneyland is a great compact park. Unfortu...  Disneyland_HongKong  \n",
              "4      the location is not in the city, took around 1...  Disneyland_HongKong  \n",
              "...                                                  ...                  ...  \n",
              "42651  i went to disneyland paris in july 03 and thou...     Disneyland_Paris  \n",
              "42652  2 adults and 1 child of 11 visited Disneyland ...     Disneyland_Paris  \n",
              "42653  My eleven year old daughter and myself went to...     Disneyland_Paris  \n",
              "42654  This hotel, part of the Disneyland Paris compl...     Disneyland_Paris  \n",
              "42655  I went to the Disneyparis resort, in 1996, wit...     Disneyland_Paris  \n",
              "\n",
              "[42656 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24a274d0-16c3-481a-b795-00a62f8c56cf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review_ID</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Year_Month</th>\n",
              "      <th>Reviewer_Location</th>\n",
              "      <th>Review_Text</th>\n",
              "      <th>Branch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>670772142</td>\n",
              "      <td>4</td>\n",
              "      <td>2019-4</td>\n",
              "      <td>Australia</td>\n",
              "      <td>If you've ever been to Disneyland anywhere you...</td>\n",
              "      <td>Disneyland_HongKong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>670682799</td>\n",
              "      <td>4</td>\n",
              "      <td>2019-5</td>\n",
              "      <td>Philippines</td>\n",
              "      <td>Its been a while since d last time we visit HK...</td>\n",
              "      <td>Disneyland_HongKong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>670623270</td>\n",
              "      <td>4</td>\n",
              "      <td>2019-4</td>\n",
              "      <td>United Arab Emirates</td>\n",
              "      <td>Thanks God it wasn   t too hot or too humid wh...</td>\n",
              "      <td>Disneyland_HongKong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>670607911</td>\n",
              "      <td>4</td>\n",
              "      <td>2019-4</td>\n",
              "      <td>Australia</td>\n",
              "      <td>HK Disneyland is a great compact park. Unfortu...</td>\n",
              "      <td>Disneyland_HongKong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>670607296</td>\n",
              "      <td>4</td>\n",
              "      <td>2019-4</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>the location is not in the city, took around 1...</td>\n",
              "      <td>Disneyland_HongKong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42651</th>\n",
              "      <td>1765031</td>\n",
              "      <td>5</td>\n",
              "      <td>missing</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>i went to disneyland paris in july 03 and thou...</td>\n",
              "      <td>Disneyland_Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42652</th>\n",
              "      <td>1659553</td>\n",
              "      <td>5</td>\n",
              "      <td>missing</td>\n",
              "      <td>Canada</td>\n",
              "      <td>2 adults and 1 child of 11 visited Disneyland ...</td>\n",
              "      <td>Disneyland_Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42653</th>\n",
              "      <td>1645894</td>\n",
              "      <td>5</td>\n",
              "      <td>missing</td>\n",
              "      <td>South Africa</td>\n",
              "      <td>My eleven year old daughter and myself went to...</td>\n",
              "      <td>Disneyland_Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42654</th>\n",
              "      <td>1618637</td>\n",
              "      <td>4</td>\n",
              "      <td>missing</td>\n",
              "      <td>United States</td>\n",
              "      <td>This hotel, part of the Disneyland Paris compl...</td>\n",
              "      <td>Disneyland_Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42655</th>\n",
              "      <td>1536786</td>\n",
              "      <td>4</td>\n",
              "      <td>missing</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>I went to the Disneyparis resort, in 1996, wit...</td>\n",
              "      <td>Disneyland_Paris</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>42656 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24a274d0-16c3-481a-b795-00a62f8c56cf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24a274d0-16c3-481a-b795-00a62f8c56cf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24a274d0-16c3-481a-b795-00a62f8c56cf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmNCLfUQAS46"
      },
      "source": [
        "Due to my available computational resources i have decided to build my on about 10 percent of the total dataset  \n",
        "\n",
        "I will be using just about 5% of the total dataset because of limitation of computation resources\n",
        "using the train_test_split method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOLgfn8w-ytw",
        "outputId": "296b477c-9496-4b65-d28c-f5238ebdfe7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(X): 2133\n",
            "len(y): 2133\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# I will be using just about 5% of the total dataset because of limitation of computation resources\n",
        "# using the train split method\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "\n",
        "X = data[['Review_Text', 'Branch']]\n",
        "\n",
        "y = data['Rating']\n",
        "\n",
        "# Create a copy of X before modifying it\n",
        "X_copy = X.copy()\n",
        "\n",
        "\n",
        "# Reduce dataset size by 80%\n",
        "X_trash, X_cut, y_trash, y_cut = train_test_split(X_copy, y, test_size=0.05, stratify=y, random_state=42)\n",
        "\n",
        "# Rename reduced dataset\n",
        "X, y = X_cut, y_cut\n",
        "\n",
        "print(f\"len(X): {len(X)}\")\n",
        "print(f\"len(y): {len(y)}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLMWF6Y6A2f7"
      },
      "source": [
        "**as explained in the previous section i will now remove columns of the dataset that are not as relevant for the prediction of the rating**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "YwVd89nAxJ03",
        "outputId": "bc5bee48-b7a4-472f-d4ad-4d56a57f748e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Review_Text  \\\n",
              "34752  Stayed between Christmas and new year.  Absolu...   \n",
              "9831   if walt disney is currently in a cryogenic cha...   \n",
              "4477   Despite what the majority of the travellers he...   \n",
              "9349   Great experience every time. I suggest that be...   \n",
              "583    We took our 1 year old to visit Hong Kong Disn...   \n",
              "...                                                  ...   \n",
              "3441   Always a great day out.  Very well maintained ...   \n",
              "13650  Had an amazing day here. We went in March and ...   \n",
              "14702  LOVE LOVE Disneyland! Must do when in the area...   \n",
              "30071  We stayed in Torcy, 3 stations away is Disneyl...   \n",
              "28399  We took two days to visit Disneyland and Disne...   \n",
              "\n",
              "                      Branch  \n",
              "34752       Disneyland_Paris  \n",
              "9831   Disneyland_California  \n",
              "4477     Disneyland_HongKong  \n",
              "9349     Disneyland_HongKong  \n",
              "583      Disneyland_HongKong  \n",
              "...                      ...  \n",
              "3441     Disneyland_HongKong  \n",
              "13650  Disneyland_California  \n",
              "14702  Disneyland_California  \n",
              "30071       Disneyland_Paris  \n",
              "28399  Disneyland_California  \n",
              "\n",
              "[2133 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88c9e964-521a-4dfa-a684-70926d25243a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review_Text</th>\n",
              "      <th>Branch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34752</th>\n",
              "      <td>Stayed between Christmas and new year.  Absolu...</td>\n",
              "      <td>Disneyland_Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9831</th>\n",
              "      <td>if walt disney is currently in a cryogenic cha...</td>\n",
              "      <td>Disneyland_California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4477</th>\n",
              "      <td>Despite what the majority of the travellers he...</td>\n",
              "      <td>Disneyland_HongKong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9349</th>\n",
              "      <td>Great experience every time. I suggest that be...</td>\n",
              "      <td>Disneyland_HongKong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>583</th>\n",
              "      <td>We took our 1 year old to visit Hong Kong Disn...</td>\n",
              "      <td>Disneyland_HongKong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3441</th>\n",
              "      <td>Always a great day out.  Very well maintained ...</td>\n",
              "      <td>Disneyland_HongKong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13650</th>\n",
              "      <td>Had an amazing day here. We went in March and ...</td>\n",
              "      <td>Disneyland_California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14702</th>\n",
              "      <td>LOVE LOVE Disneyland! Must do when in the area...</td>\n",
              "      <td>Disneyland_California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30071</th>\n",
              "      <td>We stayed in Torcy, 3 stations away is Disneyl...</td>\n",
              "      <td>Disneyland_Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28399</th>\n",
              "      <td>We took two days to visit Disneyland and Disne...</td>\n",
              "      <td>Disneyland_California</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2133 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88c9e964-521a-4dfa-a684-70926d25243a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88c9e964-521a-4dfa-a684-70926d25243a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88c9e964-521a-4dfa-a684-70926d25243a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# 'unwanted_columns' is a list of all columns which I have decided to remove\n",
        "#unwanted_columns = ['Review_ID', 'Year_Month', 'Reviewer_Location']\n",
        "#reduced_data.drop(columns=unwanted_columns)\n",
        "#final_data = reduced_data.drop(columns=unwanted_columns)\n",
        "#final_data\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "branch = X['Branch']\n",
        "branch\n",
        "\n",
        "# Perform one-hot encoding\n",
        "branch_encoded = pd.get_dummies(branch)\n",
        "#print(f\"branch_encoded.columns: {branch_encoded.columns}\")\n",
        "# drop first\n",
        "branch = branch_encoded\n",
        "branch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "kTDuG2lKuerw",
        "outputId": "7d4dbc4c-7b84-4e3c-81c2-ebd8b7c926fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Disneyland_California  Disneyland_HongKong  Disneyland_Paris\n",
              "34752                      0                    0                 1\n",
              "9831                       1                    0                 0\n",
              "4477                       0                    1                 0\n",
              "9349                       0                    1                 0\n",
              "583                        0                    1                 0\n",
              "...                      ...                  ...               ...\n",
              "3441                       0                    1                 0\n",
              "13650                      1                    0                 0\n",
              "14702                      1                    0                 0\n",
              "30071                      0                    0                 1\n",
              "28399                      1                    0                 0\n",
              "\n",
              "[2133 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61eeda92-e379-4d5e-844e-72332773c1a8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Disneyland_California</th>\n",
              "      <th>Disneyland_HongKong</th>\n",
              "      <th>Disneyland_Paris</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34752</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9831</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4477</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9349</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>583</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3441</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13650</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14702</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30071</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28399</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2133 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61eeda92-e379-4d5e-844e-72332773c1a8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61eeda92-e379-4d5e-844e-72332773c1a8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61eeda92-e379-4d5e-844e-72332773c1a8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "branch_list = [list(ohe) for ohe in branch.values]"
      ],
      "metadata": {
        "id": "MqOJ98CM5OfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "print(f\"type(branch): {type(branch)}\")\n",
        "branch = np.array(branch_list)\n",
        "print(f\"branch.shape: {branch.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9srl_Io5QTZ",
        "outputId": "021a5170-eba2-4ed7-dec3-e4c0bfbd76fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(branch): <class 'pandas.core.frame.DataFrame'>\n",
            "branch.shape: (2133, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "78SmtL7C5Q0R",
        "outputId": "3a8c3ac7-9407-4ad7-fbab-f185687107eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Review_Text  \\\n",
              "34752  Stayed between Christmas and new year.  Absolu...   \n",
              "9831   if walt disney is currently in a cryogenic cha...   \n",
              "4477   Despite what the majority of the travellers he...   \n",
              "9349   Great experience every time. I suggest that be...   \n",
              "583    We took our 1 year old to visit Hong Kong Disn...   \n",
              "...                                                  ...   \n",
              "3441   Always a great day out.  Very well maintained ...   \n",
              "13650  Had an amazing day here. We went in March and ...   \n",
              "14702  LOVE LOVE Disneyland! Must do when in the area...   \n",
              "30071  We stayed in Torcy, 3 stations away is Disneyl...   \n",
              "28399  We took two days to visit Disneyland and Disne...   \n",
              "\n",
              "                      Branch  \n",
              "34752       Disneyland_Paris  \n",
              "9831   Disneyland_California  \n",
              "4477     Disneyland_HongKong  \n",
              "9349     Disneyland_HongKong  \n",
              "583      Disneyland_HongKong  \n",
              "...                      ...  \n",
              "3441     Disneyland_HongKong  \n",
              "13650  Disneyland_California  \n",
              "14702  Disneyland_California  \n",
              "30071       Disneyland_Paris  \n",
              "28399  Disneyland_California  \n",
              "\n",
              "[2133 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c28d7a9-0fd7-493b-8f95-8cce91100fd6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review_Text</th>\n",
              "      <th>Branch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34752</th>\n",
              "      <td>Stayed between Christmas and new year.  Absolu...</td>\n",
              "      <td>Disneyland_Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9831</th>\n",
              "      <td>if walt disney is currently in a cryogenic cha...</td>\n",
              "      <td>Disneyland_California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4477</th>\n",
              "      <td>Despite what the majority of the travellers he...</td>\n",
              "      <td>Disneyland_HongKong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9349</th>\n",
              "      <td>Great experience every time. I suggest that be...</td>\n",
              "      <td>Disneyland_HongKong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>583</th>\n",
              "      <td>We took our 1 year old to visit Hong Kong Disn...</td>\n",
              "      <td>Disneyland_HongKong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3441</th>\n",
              "      <td>Always a great day out.  Very well maintained ...</td>\n",
              "      <td>Disneyland_HongKong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13650</th>\n",
              "      <td>Had an amazing day here. We went in March and ...</td>\n",
              "      <td>Disneyland_California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14702</th>\n",
              "      <td>LOVE LOVE Disneyland! Must do when in the area...</td>\n",
              "      <td>Disneyland_California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30071</th>\n",
              "      <td>We stayed in Torcy, 3 stations away is Disneyl...</td>\n",
              "      <td>Disneyland_Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28399</th>\n",
              "      <td>We took two days to visit Disneyland and Disne...</td>\n",
              "      <td>Disneyland_California</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2133 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c28d7a9-0fd7-493b-8f95-8cce91100fd6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c28d7a9-0fd7-493b-8f95-8cce91100fd6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c28d7a9-0fd7-493b-8f95-8cce91100fd6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSSacc1cBbkt"
      },
      "source": [
        "**as explained in the prevoius section I will now transform my \"rating\" column to a column of two values. After which I will study the balance between my new binary classes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr4u44KnyZAJ",
        "outputId": "243ced30-ead1-4543-c224-8ccff30906d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34752    3\n",
              "9831     3\n",
              "4477     5\n",
              "9349     5\n",
              "583      5\n",
              "        ..\n",
              "3441     5\n",
              "13650    4\n",
              "14702    5\n",
              "30071    5\n",
              "28399    5\n",
              "Name: Rating, Length: 2133, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6wyLsZhESNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "597f1ac2-947a-4009-99fb-37fc2c00ac20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34752    0\n",
              "9831     0\n",
              "4477     1\n",
              "9349     1\n",
              "583      1\n",
              "        ..\n",
              "3441     1\n",
              "13650    1\n",
              "14702    1\n",
              "30071    1\n",
              "28399    1\n",
              "Name: Rating, Length: 2133, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "def transform_values(column):\n",
        "    transformed_column = column.copy()\n",
        "    transformed_column.replace([1, 2, 3], 0, inplace=True)\n",
        "    transformed_column.replace([4, 5], 1, inplace=True)\n",
        "    return transformed_column\n",
        "\n",
        "\n",
        "y = transform_values(y)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53ZbHFtryk-B",
        "outputId": "c4238476-d905-4b37-c109-724e1e509103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    1696\n",
            "0     437\n",
            "Name: Rating, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#ratings\n",
        "counts = y.value_counts()\n",
        "\n",
        "# Display the counts\n",
        "print(counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vglRCDsfEqjz"
      },
      "source": [
        "**For each text review I am going to perform Natural Language Processing methods, such as making each word a lower case, lemmatization and tokenization and then I apply a word embedding to the text in order to feed as input to the model.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04a-jxdH11tu",
        "outputId": "f0b70cfc-3ad6-47ce-daa0-1f7eda7eebcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# using the nltk library\n",
        "# and download the neccesary nltk packages needed\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')  # Download required resources\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Get the list of stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Convert each word to lowercase, remove stopwords, and tokenize\n",
        "X['Reviewed_Text'] = X['Review_Text'].apply(lambda x: [word.lower() for word in word_tokenize(x) if word.lower() not in stop_words])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Px2oBIxi4jGJ"
      },
      "outputs": [],
      "source": [
        "np_reviews = np.array(X['Reviewed_Text'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(np_reviews)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ydYvbRgAs5i",
        "outputId": "4cb5adb2-2dc0-4e01-f084-52c48e5c26d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Bs7Qe4u4Cgi"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import requests\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# I am using GloVe for word embedding\n",
        "# so we import the file for GloVe Embedding\n",
        "# Note: The GloVe file should match the number of dimensions set\n",
        "# I imported the glove file which i saved on my onedrive and used the link and code to import it\n",
        "glove_url = 'https://1drv.ms/t/s!Ar8rswPGMOZFwlgZ2twjKZdStNOH?e=bZ5lLS'\n",
        "embedding_dim = 200\n",
        "\n",
        "# Download GloVe file\n",
        "response = requests.get(glove_url)\n",
        "glovee = response.text\n",
        "\n",
        "# introduce GloVe into the memory\n",
        "embeddings_index = {}\n",
        "\n",
        "for line in glovee.split('\\n'):\n",
        "    values = line.split()\n",
        "    if len(values) > 1:\n",
        "        word = values[0]\n",
        "        #coefs = np.asarray(values[1:], dtype='float32')\n",
        "        #embeddings_index[word] = coefs\n",
        "        try:\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "        except ValueError:\n",
        "            # Skip lines that cannot be converted to float\n",
        "            pass\n",
        "\n",
        "# Create the embedding matrix\n",
        "max_features = 500  # Maximum number of words to keep in the vocabulary\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts((np_reviews))\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "\n",
        "##sequence\n",
        "text_sequences = tokenizer.texts_to_sequences(np_reviews)\n",
        "#test_sequences = tokenizer.texts_to_sequences(np_reviews)\n",
        "\n",
        "# Pad sequences to a fixed length\n",
        "max_seq_length = 100  # Set the desired maximum sequence length\n",
        "text_data = pad_sequences(text_sequences, maxlen=max_seq_length)\n",
        "#test_data = pad_sequences(test_sequences, maxlen=max_seq_length)\n",
        "\n",
        "\n",
        "num_words = min(max_features, len(word_index) + 1)\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "  if i >= max_features:\n",
        "        continue\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knEGOG53BN_W",
        "outputId": "8b7ad18a-f429-47c3-e64c-5881ba05551a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ..., 120, 308,  52],\n",
              "       [  0,   0,   0, ..., 367, 320,   1],\n",
              "       [  0,   0,   0, ...,   3, 304,   1],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,  26, 131,   1],\n",
              "       [  0,   0,   0, ...,  94,   4,   1],\n",
              "       [  0,   0,   0, ..., 184,   8,   1]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "branch"
      ],
      "metadata": {
        "id": "yjOOPycQ-eb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"type(text_data): {type(text_data)}\")\n",
        "reviews = text_data\n",
        "print(f\"reviews.shape: {reviews.shape}\")\n"
      ],
      "metadata": {
        "id": "wIXKyQZm9jlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_array = np.concatenate((reviews, branch), axis=1)\n",
        "# Print the shape of the combined array\n",
        "print(combined_array.shape)"
      ],
      "metadata": {
        "id": "0UbF_vyuCDjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tdata = list(combined_array)\n",
        "tdata = np.array(tdata)\n",
        "\n",
        "tdata.shape, y.shape"
      ],
      "metadata": {
        "id": "EgvZ81YxG-Jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v3kvISX4W2M"
      },
      "source": [
        "Next we carry out the train and test split of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2UBCms3z0Te"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, train_ratings, test_ratings = train_test_split(tdata, ratings, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BQwqsepR9i_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnmMqzJX76gW"
      },
      "source": [
        "# Q2. How would you design the output layer;\n",
        "\n",
        "Considering the fact that I am working with binary classfication:\n",
        "\n",
        "The output layer of a binary classification model for text classification is a single unit because it represents likelihood of the input belonging to one of the two classes, i.e. 0 OR 1.\n",
        "\n",
        "The sigmoid function will be applied to the output layer because it gives values between 0 and 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SckYtIH0BgQH"
      },
      "source": [
        "# QUESTION 3 AND 4\n",
        "**3. Which activation functions and which Loss function would you use;**\n",
        "\n",
        "**4. Which (possible) regularizers, initializers, normalizers, etc., and why;**\n",
        "\n",
        "**The activation functions **for the hidden layers will be between the *sigmoid activation function, the Hyperbolic Tangent (tanh) and the RelU activation function*, I will run the model will each one to see which one performs best, they will also be hyperparameter tuned.\n",
        "**The loss Function**, considering that it is a binary classfication model, will be the** binary cross-entropy**. I will also research and experiment with others such as the hinge and square_hinge\n",
        "\n",
        "**Regularizers:** Regularization techniques such as **L1 or L2** regularization can be applied to prevent overfitting by adding a penalty term to the loss. ***(an addition to my exam paper, I stated I will use just dropout but dropout is a weight regularization technique and not an actual regularizer)***\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, GRU, Flatten, Dense, BatchNormalization, Dropout, Concatenate, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def create_model(gru_hid_1,gru_hid_2,\n",
        "                 input_shape=None,\n",
        "                 output_shape=None,\n",
        "                 input_length=None,\n",
        "                 embedding_matrix=None,\n",
        "                 learning_rate=10**-1,\n",
        "                 loss='binary_crossentropy',\n",
        "                 rnn_act='tanh',\n",
        "                 hid_act='relu',\n",
        "                 out_act='sigmoid',\n",
        "                 dropout_rate=0.1,\n",
        "                 kernel_regularizer='l1',\n",
        "                 optimizer='adam'):\n",
        "\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    reviews = Lambda(lambda x: x[:, :101])(input_layer)\n",
        "    part_2 = Lambda(lambda x: x[:, 101:])(input_layer)\n",
        "\n",
        "    # Model instantiation\n",
        "\n",
        "    embedding = Embedding(input_dim=embedding_matrix.shape[0],  # Replace with the correct value\n",
        "                          output_dim=embedding_matrix.shape[1],  # Replace with the correct value\n",
        "                          weights=[embedding_matrix],\n",
        "                          input_length=input_length,\n",
        "                          trainable=False)(reviews)\n",
        "\n",
        "    rnn1 = GRU(\n",
        "        units=gru_hid_1,\n",
        "        activation=rnn_act,\n",
        "        kernel_regularizer=kernel_regularizer,\n",
        "        dropout=dropout_rate,\n",
        "        return_sequences=True\n",
        "    )(embedding)\n",
        "\n",
        "    rnn2 = GRU(\n",
        "        units=gru_hid_2,\n",
        "        activation=rnn_act,\n",
        "        kernel_regularizer=kernel_regularizer,\n",
        "        dropout=dropout_rate,\n",
        "        return_sequences=True\n",
        "    )(rnn1)\n",
        "\n",
        "\n",
        "    flatten = Flatten()(rnn2)\n",
        "\n",
        "    concat = Concatenate()([flatten, part_2])  # Concatenate flatten and part_2 inputs\n",
        "\n",
        "\n",
        "    hidden_layer = Dense(\n",
        "        units=gru_hid_2,\n",
        "        activation=hid_act,\n",
        "        kernel_regularizer=kernel_regularizer\n",
        "    )(concat)\n",
        "\n",
        "    hidden_layer2 = Dense(\n",
        "        units=gru_hid_2,\n",
        "        activation=hid_act,\n",
        "        kernel_regularizer=kernel_regularizer\n",
        "    )(hidden_layer)\n",
        "\n",
        "\n",
        "    output_layer = Dense(\n",
        "        units=output_shape,\n",
        "        activation=out_act\n",
        "    )(hidden_layer2)\n",
        "\n",
        "    # Model instantiation\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    # Model compile\n",
        "    model.compile(\n",
        "        loss=loss,\n",
        "        optimizer=optimizer,\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "1HnAbhasKI-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(gru_hid_1=64, gru_hid_2=64,\n",
        "                 input_shape=(103,),\n",
        "                 output_shape=1,\n",
        "                 input_length=100,\n",
        "                 embedding_matrix=embedding_matrix\n",
        ")\n",
        "model.fit(X_train, train_ratings, epochs=5)"
      ],
      "metadata": {
        "id": "iIXAwH2jLIbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "id": "kanGs6snNkam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vP3mj4zyadxp"
      },
      "outputs": [],
      "source": [
        "# installing scikeras is neccesary for using an effective KerasClassifier\n",
        "! pip install scikeras\n",
        "import tensorflow as tf\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import legacy\n",
        "\n",
        "embedding = Embedding(input_dim=embedding_matrix.shape[0],  # Replace with the correct value\n",
        "                          output_dim=embedding_matrix.shape[1],  # Replace with the correct value\n",
        "                          weights=[embedding_matrix],\n",
        "                          input_length=input_length,\n",
        "                          trainable=False)(reviews)\n",
        "\n",
        "embedding_dim = 200  # Dimensionality of the word embeddings\n",
        "dropout_rate = 0.2  # Dropout rate to prevent overfitting\n",
        "regularizer = 'l2' # weight regularizer\n",
        "learning_rate = 0.001 # the learning rate\n",
        "\n",
        "optimizer = legacy.Adam(learning_rate=learning_rate) # Set the learning rate for the optimizer # also with the adam optimizer.\n",
        "\n",
        "def create_model(hid1, hid2,\n",
        "                 learning_rate= 10**-1,\n",
        "                 loss='BinaryCrossentropy',\n",
        "                 hid_act='tanh',\n",
        "                 hid_act2='relu',\n",
        "                 hid_act3='sigmoid',\n",
        "                 out_act='sigmoid',\n",
        "                 dropout_rate=0.2,\n",
        "                 weight_reg=None):\n",
        "  # learning_rate: the learning rate to be used by the optimizer\n",
        "  # hid1: number of neurons in the first hidden layer\n",
        "  # hid2: number of neurons in the second hidden layer\n",
        "  # loss: loss function\n",
        "  # hid_act,2,3: activation functions to be considered and experimented for the hidden layers\n",
        "  # out_act: activation function for output layer\n",
        "  # dropout_rate: the rate of dropout to be used\n",
        "\n",
        "  model = Sequential()\n",
        "  #model.add(Embedding(len(tokenizer.word_index) + 1, embedding_dim, input_length=max_seq_length))\n",
        "  model.add(Embedding(input_dim=embedding_matrix.shape[0],  # Replace with the correct value\n",
        "                          output_dim=embedding_matrix.shape[1],  # Replace with the correct value\n",
        "                          weights=[embedding_matrix],\n",
        "                          input_length=input_length,\n",
        "                          trainable=False))\n",
        "  model.add(GRU(hid1, activation=hid_act, return_sequences=True, kernel_regularizer=regularizer))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "  model.add(GRU(hid2, activation=hid_act3 , kernel_regularizer=regularizer))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "  model.add(Dense(1, activation=out_act))  ## output layer\n",
        "  model.compile(loss=loss,\n",
        "        optimizer=optimizer,\n",
        "        metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model,\n",
        "                        hid1 = 16,\n",
        "                        hid2=8,\n",
        "                        epochs=5)\n",
        "\n",
        "\n",
        "model.fit(X_train, train_ratings, batch_size=32)\n",
        "# test run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz1dOQOcGRhB"
      },
      "source": [
        "# QUESTION 5\n",
        "\n",
        "**On which hyperparameters would you perform the model selection (if any), or why you would not perform it.**\n",
        "\n",
        "1. The NUMBER OF HIDDEN LAYERS\n",
        "2. THE DROPOUT RATE\n",
        "3. THE LEARNING RATE\n",
        "4. THE BATCH SIZE TO BE USED\n",
        "5. THE WEIGHT REGULARIZER TO BE USED\n",
        "6. THE LOSS FUNCTION\n",
        "7. THE ACTIVATION FUNCTION TO BE USED IN THE HIDDEN LAYERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSR-TydGHo6O"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split,  StratifiedKFold, GridSearchCV\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "model = KerasClassifier(model=create_model,\n",
        "                        hid1 = 8,\n",
        "                        hid2 = 8,\n",
        "                        learning_rate = 0.001,\n",
        "                        hid_act= 'sigmoid',\n",
        "                        dropout_rate=0.2,\n",
        "                        epochs = 10)\n",
        "\n",
        "# THE CHOICE FOR POSSIBLE HIDDEN LAYER COMBINATIONS\n",
        "hid1 = [32, 16]\n",
        "hid2 = [16, 8]\n",
        "param_grid = dict(model__hid1= hid1, model__hid2= hid2)\n",
        "\n",
        "## define the grid search parameters for the number of hidden layers\n",
        "\n",
        "GS = GridSearchCV(estimator=model, param_grid=param_grid,\n",
        "                  n_jobs=-1, cv=3)\n",
        "\n",
        "grid_result = GS.fit(train_data, train_ratings, batch_size=16)\n",
        "# best result\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_,\n",
        "                             grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "# printing results for all combinations\n",
        "for mean, param in zip(means, params):\n",
        "    print(f\"{mean} \\t with: {param}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRIcjWjKOIlu"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split,  StratifiedKFold, GridSearchCV\n",
        "\n",
        "model = KerasClassifier(model=create_model,\n",
        "                        hid1 = 16,\n",
        "                        hid2 = 8,\n",
        "                        learning_rate = 0.001,\n",
        "                        hid_act= 'sigmoid',\n",
        "                        dropout_rate=0.2,\n",
        "                        epochs = 10)\n",
        "\n",
        "\n",
        "dropout = [0.1, 0.2, 0.3]\n",
        "param_grid = dict(model__dropout_rate= dropout)\n",
        "\n",
        "## define the grid search parameters for the dropout rate\n",
        "GS = GridSearchCV(estimator=model, param_grid=param_grid,\n",
        "                  n_jobs=-1, cv=3)\n",
        "\n",
        "grid_result = GS.fit(train_data, train_ratings, batch_size=32)\n",
        "# best result\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_,\n",
        "                             grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "# printing results for all combinations\n",
        "for mean, param in zip(means, params):\n",
        "    print(f\"{mean} \\t with: {param}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEVsUds9n75L"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split,  StratifiedKFold, GridSearchCV\n",
        "\n",
        "model = KerasClassifier(model=create_model,\n",
        "                        hid1 = 16,\n",
        "                        hid2 = 8,\n",
        "                        learning_rate = 0.001,\n",
        "                        hid_act= 'sigmoid',\n",
        "                        dropout_rate=0.2,\n",
        "                        epochs = 10)\n",
        "\n",
        "\n",
        "lr = [10**-4, 10**-3, 10**-2, 10**-1]\n",
        "param_grid = dict(model__learning_rate= lr)\n",
        "\n",
        "## define the grid search parameters for the learning rate to be used\n",
        "GS = GridSearchCV(estimator=model, param_grid=param_grid,\n",
        "                  n_jobs=-1, cv=3)\n",
        "\n",
        "grid_result = GS.fit(train_data, train_ratings, batch_size=32)\n",
        "# best result\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_,\n",
        "                             grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "# printing results for all combinations\n",
        "for mean, param in zip(means, params):\n",
        "    print(f\"{mean} \\t with: {param}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S75SX-tNOIlt"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split,  StratifiedKFold, GridSearchCV\n",
        "\n",
        "model = KerasClassifier(model=create_model,\n",
        "                        hid1 = 16,\n",
        "                        hid2 = 8,\n",
        "                        learning_rate = 0.001,\n",
        "                        hid_act= 'sigmoid',\n",
        "                        dropout_rate=0.2,\n",
        "                        epochs = 10)\n",
        "\n",
        "\n",
        "batch_size = [16, 32, 64]\n",
        "param_grid = dict(batch_size=batch_size)\n",
        "\n",
        "## define the grid search parameters for the batch size to be used\n",
        "GS = GridSearchCV(estimator=model, param_grid=param_grid,\n",
        "                  n_jobs=-1, cv=3)\n",
        "\n",
        "grid_result = GS.fit(train_data, train_ratings, batch_size=32)\n",
        "# best result\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_,\n",
        "                             grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "# printing results for all combinations\n",
        "for mean, param in zip(means, params):\n",
        "    print(f\"{mean} \\t with: {param}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qn3hpePzOIlt"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split,  StratifiedKFold, GridSearchCV\n",
        "\n",
        "model = KerasClassifier(model=create_model,\n",
        "                        hid1 = 16,\n",
        "                        hid2 = 8,\n",
        "                        learning_rate = 0.001,\n",
        "                        hid_act= 'sigmoid',\n",
        "                        dropout_rate=0.2,\n",
        "                        epochs = 10)\n",
        "\n",
        "\n",
        "weight_reg = [None, 'l1', 'l2']\n",
        "param_grid = dict(model__weight_reg= weight_reg)\n",
        "\n",
        "## define the grid search parameters for the weight regularizer to be used\n",
        "GS = GridSearchCV(estimator=model, param_grid=param_grid,\n",
        "                  n_jobs=-1, cv=3)\n",
        "\n",
        "grid_result = GS.fit(train_data, train_ratings, batch_size=32)\n",
        "# best result\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_,\n",
        "                             grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "# printing results for all combinations\n",
        "for mean, param in zip(means, params):\n",
        "    print(f\"{mean} \\t with: {param}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vt2_nRg-C2q"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "model = KerasClassifier(model=create_model,\n",
        "                        hid1 = 8,\n",
        "                        hid2 = 8,\n",
        "                        learning_rate = 0.001,\n",
        "                        hid_act= 'sigmoid',\n",
        "                        dropout_rate=0.2,\n",
        "                        epochs = 10)\n",
        "\n",
        "\n",
        "hid_act = ['relu', 'tanh', 'sigmoid']\n",
        "param_grid = dict(model__hid_act= hid_act)\n",
        "\n",
        "## define the grid search parameters for the possible activation function for the hidden layer\n",
        "GS = GridSearchCV(estimator=model, param_grid=param_grid,\n",
        "                  n_jobs=-1, cv=3)\n",
        "\n",
        "grid_result = GS.fit(train_data, train_ratings, batch_size=16)\n",
        "# best result\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_,\n",
        "                             grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "# printing results for all combinations\n",
        "for mean, param in zip(means, params):\n",
        "    print(f\"{mean} \\t with: {param}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JybhIn2ns17e"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split,  StratifiedKFold, GridSearchCV\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "model = KerasClassifier(model=create_model,\n",
        "                        hid1 = 8,\n",
        "                        hid2 = 8,\n",
        "                        learning_rate = 0.001,\n",
        "                        hid_act= 'sigmoid',\n",
        "                        dropout_rate=0.2,\n",
        "                        epochs = 10)\n",
        "\n",
        "loss = ['binary_crossentropy', 'hinge', 'squared_hinge']\n",
        "param_grid = dict(model__loss= loss)\n",
        "\n",
        "## define the grid search parameters for the loss function to be used\n",
        "GS = GridSearchCV(estimator=model, param_grid=param_grid,\n",
        "                  n_jobs=-1, cv=3)\n",
        "\n",
        "grid_result = GS.fit(train_data, train_ratings, batch_size=16)\n",
        "# best result\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_,\n",
        "                             grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "# printing results for all combinations\n",
        "for mean, param in zip(means, params):\n",
        "    print(f\"{mean} \\t with: {param}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CJzZ5CO7l8q"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense, Embedding\n",
        "\n",
        "\n",
        "## define the final model with the results from the tuning of hyperparameters ###\n",
        "\n",
        "def final_gru(embedding_dim,\n",
        "              dropout_rate,\n",
        "              regularization,\n",
        "             learning_rate):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(len(tokenizer.word_index) + 1, embedding_dim, input_length=max_seq_length))\n",
        "\n",
        "  model.add(GRU(32, activation='relu', return_sequences=True, kernel_regularizer=None))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "\n",
        "  model.add(GRU(16, activation='sigmoid', kernel_regularizer=None))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  optimizer = legacy.Adam(learning_rate=learning_rate)\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "embedding_dim = 200  # Dimensionality of the word embeddings\n",
        "dropout_rate = 0.1  # Dropout rate to prevent overfitting\n",
        "regularization = None  # as seen after hyperparameter tuning\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "model = final_gru(embedding_dim, dropout_rate, regularization, learning_rate)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWYmSCtpGcNY"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_data, train_ratings, batch_size=16, epochs=10, validation_data=(test_data, test_ratings))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKn-6i7RnPUr"
      },
      "source": [
        "# QUESTION 6\n",
        "\n",
        "6. How would you evalaute the generalization capabilties of the model on\n",
        "unseen data?\n",
        "\n",
        " To evaluate the generalization capabilities of the GRU model on unseen data, a common practice is to split the available data into training, validation, and test sets. The model is trained on the training set, and the performance is evaluated on the validation set during the training process. Once the model is trained, its final performance is assessed on the test set, which represents unseen data. Metrics such as accuracy could be used to evaluate the model.\n",
        "\n",
        " i.e. validation_data=(test_data, test_ratings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5HSOrZwG0kx"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(test_data, test_ratings) # i.e. the validation set\n",
        "print('Test Loss:', loss)\n",
        "print('Test Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Him15KNoKr7R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "d64ec381008948dcb6b8c1b4600dc84f",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}